{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This version consider children dependency when people <16 are in the household\n",
    "\n",
    "## before, this value was < 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read PSU file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psu_dir = r'' # use your path\n",
    "\n",
    "\n",
    "df_psu = pd.read_csv(\n",
    "    psu_dir,\n",
    "    sep='\\t',\n",
    "    usecols=['SurveyYear', 'PSUID', 'PSUGOR_B02ID'],\n",
    "#     dtype={\"W5\": np.float64,}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_psu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select those PSU areas relevant for the project (all England except London)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only those areas that are England except London\n",
    "#Value = 1.0\tLabel = North East\n",
    "#Value = 2.0\tLabel = North West\n",
    "#Value = 3.0\tLabel = Yorkshire and the Humber\n",
    "#Value = 4.0\tLabel = East Midlands\n",
    "#Value = 5.0\tLabel = West Midlands\n",
    "#Value = 6.0\tLabel = East of England\n",
    "#Value = 7.0\tLabel = London\n",
    "#Value = 8.0\tLabel = South East\n",
    "#Value = 9.0\tLabel = South West\n",
    "#Value = 10.0\tLabel = Wales\n",
    "#Value = 11.0\tLabel = Scotland\n",
    "#Value = -10.0\tLabel = DEAD\n",
    "#Value = -9.0\tLabel = DNA\n",
    "#Value = -8.0\tLabel = NA\n",
    "\n",
    "area_list = [1,2,3,4,5,6,8,9]\n",
    "\n",
    "df_psu_area = df_psu[df_psu['PSUGOR_B02ID'].isin(area_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_psu_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read day file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the file with the days related to each individual\n",
    "days_dir = r'' # use your path\n",
    "\n",
    "\n",
    "df_days = pd.read_csv(\n",
    "    days_dir,\n",
    "    sep='\\t',\n",
    "    usecols=['DayID',               # ID given to all trips made by an individual on a given travel day - Created in SQL\n",
    "             'IndividualID',        # Individual unique ID - Created in SQL\n",
    "             'HouseholdID',         # Household unique ID - Created in SQL\n",
    "             'PSUID',               # PSU unique ID - Created in SQL\n",
    "             'TravelWeekDay_B01ID', # Day of week trip took place\n",
    "             'TravelDayType_B01ID', # Type of day trip took place on (2008 onwards)\n",
    "             'TravelMonth_B01ID',   # Month of year trip took place - coded month\n",
    "             'TravelYear',          # Year of trip\n",
    "             'TravelDate']          # Trip date      \n",
    ")\n",
    "#persons_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all persons unique ID values\n",
    "psu_area_list = df_psu_area['PSUID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only those days that are within the PSU and were done during \"school term-time\" (TravelDayType_B01ID = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only those days that belong to the people selected (2012-2019 and all England except London)\n",
    "df_days_NTS = df_days.loc[(df_days['PSUID'].isin(psu_area_list)) &\n",
    "                         (df_days['TravelYear'] >= 2011) &\n",
    "                         (df_days['TravelYear'] <= 2019) & \n",
    "                         (df_days['TravelDayType_B01ID'] == 3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_days_NTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_days_NTS['TravelDate'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_days_NTS['TravelDate'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all persons unique ID values\n",
    "days_persons_NTS_list = df_days_NTS['IndividualID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(days_persons_NTS_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "days_persons_NTS_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all PSU unique ID values\n",
    "days_PSU_NTS_list = df_days_NTS['PSUID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only those PSU that belong to days_PSU_NTS_list\n",
    "df_psu_NTS = df_psu_area.loc[(df_psu_area['PSUID'].isin(days_PSU_NTS_list))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_psu_NTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read individuals file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_dir = r'' # use your path\n",
    "\n",
    "\n",
    "df_persons = pd.read_csv(\n",
    "    persons_dir,\n",
    "    sep='\\t',\n",
    "    usecols=['SurveyYear',          # survey year \n",
    "             'IndividualID',        # person unique ID\n",
    "             'HouseholdID',         # household unique ID \n",
    "             'PSUID',               # PSU unique ID\n",
    "             'Age',                 # Age (numeric)\n",
    "             'Sex_B01ID',           # Sex \n",
    "             'MarStat_B01ID',       # Marital status \n",
    "             'DrivLic_B01ID',       # Driving licence\n",
    "             'CarAccess_B01ID',     # Car access\n",
    "             'OwnCycle_B01ID',      # Own or use a bicycle until 2017\n",
    "             'OwnCycleN_B01ID',     # Own or use a bicycle from 2018\n",
    "             'IndIncome2002_B01ID', # Individual Income - 2002 bandings - 23 categories\n",
    "             'EcoStat_B01ID',       # Working status of individual - 11 categories\n",
    "             'XSOC2010_B02ID']      # Standard Occupational Classification (SOC) - 2010 classification - summary - 9 categories\n",
    ")\n",
    "#persons_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only those days that belong to the people selected (2012-2019 and all England except London)\n",
    "df_persons_NTS = df_persons.loc[(df_persons['IndividualID'].isin(days_persons_NTS_list))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_persons_NTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of NTS people (assuming each trip belongs to a different person) and SPENSER people: \n",
    "450517/2645517*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if those individuals selected are within the time and geographical frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_persons_NTS.loc[~df_persons_NTS['PSUID'].isin(psu_area_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_persons_NTS.loc[~df_persons_NTS['IndividualID'].isin(days_persons_NTS_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start updating column names and attribute values in order to be used later with SPENSER data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS.rename(\n",
    "    columns={  # rename data\n",
    "        'Sex_B01ID': 'Sex',\n",
    "        'MarStat_B01ID': 'Marital_status',\n",
    "        'OwnCycle_B01ID': 'Bike_access2018',\n",
    "        'DrivLic_B01ID': 'Driving_license',\n",
    "        'CarAccess_B01ID': 'Car_access',\n",
    "        'IndIncome2002_B01ID': 'Income',\n",
    "        'EcoStat_B01ID': 'Economic_activity',\n",
    "        'XSOC2010_B02ID': 'Occupation',\n",
    "        'OwnCycleN_B01ID': 'Bike_access2019'\n",
    "    },\n",
    "                inplace=True)\n",
    "\n",
    "#persons_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check attributes of each column (values and type):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Marital status\" has:\n",
    "c = df_persons_NTS['Sex'].unique()\n",
    "print(sorted(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Sex'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Marital status\" has:\n",
    "d = df_persons_NTS['Age'].unique()\n",
    "print(sorted(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Age'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marital status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Marital status\" has:\n",
    "e = df_persons_NTS['Marital_status'].unique()\n",
    "print(sorted(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS.groupby('Marital_status').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Marital status values need to be updated in order to match them with SPENSER data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values of the marital status\n",
    "\n",
    "## 'DNA' was observed that is related to people aged 0 - 15. So they are going to be considered as 'Single'.\n",
    "## There were found 4 'NA' people. These are going to be considered as 'Single' too.\n",
    "\n",
    "marital_status_update = {\n",
    "    1: 'Married or couple', # Married and living with spouse\n",
    "    2: 'Single',            # Seperated\n",
    "    3: 'Single',            # Single\n",
    "    4: 'Single',            # Divorced\n",
    "    5: 'Single',            # Widowed\n",
    "    -9: 'Single',           # 'DNA'\n",
    "    -8: 'Single'            # 'NA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Marital_status'] = df_persons_NTS['Marital_status'].map(marital_status_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique updated values\n",
    "e = df_persons_NTS['Marital_status'].unique()\n",
    "print(sorted(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Marital_status').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Marital_status'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economic activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Economic activity\" has:\n",
    "f = df_persons_NTS['Economic_activity'].unique()\n",
    "print(sorted(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS.groupby('Economic_activity').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Economic activity values need to be updated in order to match them with SPENSER data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values of the marital status\n",
    "\n",
    "##  ((-9)'DNA') was observed that is related to people aged 0 - 15. So they are going to be considered as \"Inactive-Child student\".\n",
    "## There were found 4 'NA' people. These are going to be considered as 'Single' too.\n",
    "\n",
    "economic_activity_update = {\n",
    "    1: 'Employed',                               # Employees: full-time\n",
    "    2: 'Employed',                               # Employees: part-time\n",
    "    3: 'Employed',                               # Self-employed: full-time\n",
    "    4: 'Employed',                               # Self-employed: part-time\n",
    "    5: 'Unemployed',                             # ILO unemployed\n",
    "    6: 'Inactive Retired',                       # Economically inactive: Retired\n",
    "    7: 'Inactive Student',                       # Economically inactive: Student\n",
    "    8: 'Inactive Looking after home family',     # Economically inactive: Looking after family / home\n",
    "    9: 'Inactive Sick',                          # Economically inactive: Permanently sick / disabled\n",
    "    10: 'Inactive Sick',                         # Economically inactive: Temporarily sick / injured\n",
    "    11: 'Inactive Other',                        # Economically inactive: Other\n",
    "    -9: 'Inactive Child student'                 # 'DNA' (individuals aged 0-15)    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Economic_activity'] = df_persons_NTS['Economic_activity'].map(economic_activity_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique updated values\n",
    "f = df_persons_NTS['Economic_activity'].unique()\n",
    "print(sorted(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Economic_activity'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Economic_activity').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Income\" has:\n",
    "g = df_persons_NTS['Income'].unique()\n",
    "print(sorted(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS.groupby('Income').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Income values need to be updated in order to match them with SPENSER data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, generate a random income value for each agent based on the income band each one is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Income_value = {\n",
    "    1: random.randint(1,999),              # Less than 1000 \n",
    "    2: random.randint(1000,1999),          # 1000- 1999\n",
    "    3: random.randint(2000,2999),          # 2000- 2999\n",
    "    4: random.randint(3000,3999),          # 3000- 3999\n",
    "    5: random.randint(4000,4999),          # 4000- 4999\n",
    "    6: random.randint(5000,5999),          # 5000- 5999\n",
    "    7: random.randint(6000,6999),          # 6000- 6999\n",
    "    8: random.randint(7000,7999),          # 7000- 7999\n",
    "    9: random.randint(8000,8999),          # 8000- 8999\n",
    "    10: random.randint(9000,9999),         # 9000- 9999\n",
    "    11: random.randint(10000,12499),       # 10000- 12499\n",
    "    12: random.randint(12500,14999),       # 12500- 14999\n",
    "    13: random.randint(15000,17499),       # 15000- 17499\n",
    "    14: random.randint(17500,19999),       # 17500- 19999\n",
    "    15: random.randint(20000,24999),       # 20000- 24999\n",
    "    16: random.randint(25000,29999),       # 25000- 29999\n",
    "    17: random.randint(30000,34999),       # 30000- 34999\n",
    "    18: random.randint(35000,39999),       # 35000- 39999\n",
    "    19: random.randint(40000,49999),       # 40000- 49999\n",
    "    20: random.randint(50000,59999),       # 50000- 59999\n",
    "    21: random.randint(60000,69999),       # 60000- 69999\n",
    "    22: random.randint(70000,74999),       # 70000- 74999\n",
    "    23: random.randint(75000,99999),       # 75000 to 99999\n",
    "    24: random.randint(100000,124999),     # 100000 to 124999\n",
    "    25: random.randint(125000,149999),     # 125000 to 149999\n",
    "    26: random.randint(150000,300000),     # 150000 or more\n",
    "    -9: 0                                  # 'DNA' (individuals aged 0-15) \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate the random income value in the band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Income_value'] = 0\n",
    "\n",
    "for idx_person, person in df_persons_NTS.iterrows():\n",
    "\n",
    "    if (person['Income'] ==  1):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(1,999)\n",
    "    elif (person['Income'] ==  2):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(1000,1999)\n",
    "    elif (person['Income'] ==  3):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(2000,2999)\n",
    "    elif (person['Income'] ==  4):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(3000,3999)\n",
    "    elif (person['Income'] ==  5):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(4000,4999)\n",
    "    elif (person['Income'] ==  6):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(5000,5999)\n",
    "    elif (person['Income'] ==  7):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(6000,6999)\n",
    "    elif (person['Income'] ==  8):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(7000,7999)\n",
    "    elif (person['Income'] ==  9):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(8000,8999)\n",
    "    elif (person['Income'] ==  10):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(9000,9999)\n",
    "    elif (person['Income'] ==  11):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(10000,12499)\n",
    "    elif (person['Income'] ==  12):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(12500,14999)\n",
    "    elif (person['Income'] ==  13):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(15000,17499)\n",
    "    elif (person['Income'] ==  14):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(17500,19999)\n",
    "    elif (person['Income'] ==  15):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(20000,24999)\n",
    "    elif (person['Income'] ==  16):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(25000,29999)\n",
    "    elif (person['Income'] ==  17):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(30000,34999)\n",
    "    elif (person['Income'] ==  18):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(35000,39999)\n",
    "    elif (person['Income'] ==  19):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(40000,49999)\n",
    "    elif (person['Income'] ==  20):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(50000,59999)\n",
    "    elif (person['Income'] ==  21):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(60000,69999)\n",
    "    elif (person['Income'] ==  22):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(70000,74999)\n",
    "    elif (person['Income'] ==  23):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(75000,99999)\n",
    "    elif (person['Income'] ==  24):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(100000,124999)\n",
    "    elif (person['Income'] ==  25):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(125000,149999)\n",
    "    elif (person['Income'] ==  26):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = random.randint(150000,300000)\n",
    "    elif (person['Income'] == -9):\n",
    "        df_persons_NTS.at[idx_person,'Income_value'] = 0\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select those people that has an income (income > 0)\n",
    "\n",
    "df_persons_NTS_income = df_persons_NTS.loc[(df_persons_NTS['Income_value'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_persons_NTS_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentiles of those people earning more than 0\n",
    "percentile_20 = int(df_persons_NTS_income.Income_value.quantile(0.2))\n",
    "percentile_40 = int(df_persons_NTS_income.Income_value.quantile(0.4))\n",
    "percentile_60 = int(df_persons_NTS_income.Income_value.quantile(0.6))\n",
    "percentile_80 = int(df_persons_NTS_income.Income_value.quantile(0.8))\n",
    "percentile_100 = int(df_persons_NTS_income.Income_value.quantile(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(percentile_20)\n",
    "print(percentile_40)\n",
    "print(percentile_60)\n",
    "print(percentile_80)\n",
    "print(percentile_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income per groups\n",
    "\n",
    "## Example: group_1 contains the 10% of those people with the lowest income (excluding those people which income = 0)\n",
    "## Example: group_10 contains the 10% of those people with the highest income\n",
    "\n",
    "df_persons_NTS['Income_group'] = ''\n",
    "\n",
    "\n",
    "for idx_person, person in df_persons_NTS.iterrows():\n",
    "    \n",
    "    if (person['Income_value'] == 0.0):\n",
    "        df_persons_NTS.at[idx_person,'Income_group'] = 'group_0'\n",
    "    \n",
    "    elif ((person['Income_value'] > 0) and \n",
    "          (person['Income_value'] <= percentile_20)):\n",
    "        df_persons_NTS.at[idx_person,'Income_group'] = 'group_1'\n",
    "    \n",
    "    elif ((person['Income_value'] > percentile_20) and \n",
    "          (person['Income_value'] <= percentile_40)):\n",
    "        df_persons_NTS.at[idx_person,'Income_group'] = 'group_2'  \n",
    "        \n",
    "    elif ((person['Income_value'] > percentile_40) and\n",
    "          (person['Income_value'] <= percentile_60)):\n",
    "        df_persons_NTS.at[idx_person,'Income_group'] = 'group_3'   \n",
    "        \n",
    "    elif ((person['Income_value'] > percentile_60) and \n",
    "          (person['Income_value'] <= percentile_80)):\n",
    "        df_persons_NTS.at[idx_person,'Income_group'] = 'group_4'\n",
    "        \n",
    "    elif ((person['Income_value'] > percentile_80) and \n",
    "          (person['Income_value'] <= percentile_100)):\n",
    "        df_persons_NTS.at[idx_person,'Income_group'] = 'group_5'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Income_new\" has:\n",
    "d = df_persons_NTS['Income_group'].unique()\n",
    "print(sorted(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Income_group').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Income_group'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Income_group'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driving license:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique updated values\n",
    "h = df_persons_NTS['Driving_license'].unique()\n",
    "print(sorted(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Driving_license').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Driving license values need to be updated in order to match them with SPENSER data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values of the driving licence\n",
    "\n",
    "## 'DNA' was observed that is related to people aged 0 - 15. So they are going to be considered as 'False'.\n",
    "## There were found 106 'NA' (-8) people. These are going to be considered as 'False' too.\n",
    "\n",
    "Driving_license_update = {\n",
    "    1: True,          # Full - car / motorcycle\n",
    "    2: True,          # Full - car only\n",
    "    3: True,          # Full - car only (automatic)\n",
    "    4: True,          # Full - car only (adapted)\n",
    "    5: False,         # Full - motorcycle only\n",
    "    6: False,         # Full - moped\n",
    "    7: True,          # Full - invalid vehicle\n",
    "    8: True,          # Full - no details\n",
    "    9: True,          # Provisional - car / motorcycle\n",
    "    10: True,         # Provisional - car\n",
    "    11: True,         # Provisional - invalid car\n",
    "    12: True,         # Provisional - other\n",
    "    13: True,         # Provisional - no details\n",
    "    14: False,        # None\n",
    "    -9: False,        # 'DNA' (individuals aged 0-15) \n",
    "    -8: False         # 'NA' \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Driving_license'] = df_persons_NTS['Driving_license'].map(Driving_license_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique updated values\n",
    "h = df_persons_NTS['Driving_license'].unique()\n",
    "print(sorted(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Driving_license').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Driving_license'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Marital status\" has:\n",
    "i = df_persons_NTS['Car_access'].unique()\n",
    "print(sorted(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Car_access').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Car access values need to be updated in order to match them with SPENSER data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values of the car access\n",
    "\n",
    "## 'DNA' (-9) was observed that is related to people aged 0 - 15. So they are going to be considered as 'False'.\n",
    "## There were found 146 'NA' (-8) people. These are going to be considered as 'False' too.\n",
    "\n",
    "Car_access_update = {\n",
    "    1: True,          # Main driver of company car\n",
    "    2: True,          # Other main driver\n",
    "    3: True,          # Not main driver of household car\n",
    "    4: False,          # Household car but non driver\n",
    "    5: False,         # Driver but no car\n",
    "    6: False,         # Non driver and no car\n",
    "    -9: False,        # 'DNA' (individuals aged 0-15) \n",
    "    -8: False         # 'NA' \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Car_access'] = df_persons_NTS['Car_access'].map(Car_access_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique updated values\n",
    "i = df_persons_NTS['Car_access'].unique()\n",
    "print(sorted(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Car_access').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Car_access'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Marital status\" has:\n",
    "j = df_persons_NTS['Bike_access2018'].unique()\n",
    "print(sorted(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Bike_access2018').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Marital status\" has:\n",
    "k = df_persons_NTS['Bike_access2019'].unique()\n",
    "print(sorted(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Bike_access2019').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike access (up to 2018) values need to be updated in order to match them with SPENSER data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values of the car access\n",
    "\n",
    "## 'DNA' (-9) was observed that is related to people aged 0 - 15. So they are going to be considered as 'False'.\n",
    "## There were found 146 'NA' (-8) people. These are going to be considered as 'False' too.\n",
    "\n",
    "Bike_access_2018_update = {\n",
    "    1: True,          # Own a bicycle yourself\n",
    "    2: True,          # Have use of household bicycle\n",
    "    3: True,          # Have use of non-household bicycle\n",
    "    4: False,         # Have no use of a bicycle\n",
    "    -10: 'no',        # DEAD\n",
    "    -9: False,        # 'DNA' (individuals aged 0-15) \n",
    "    -8: False         # 'NA' \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Bike_access2018'] = df_persons_NTS['Bike_access2018'].map(Bike_access_2018_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Marital status\" has:\n",
    "j = df_persons_NTS['Bike_access2018'].unique()\n",
    "print((j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Bike_access2018').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bike access (from 2019) values need to be updated in order to match them with SPENSER data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values of the car access\n",
    "\n",
    "## 'DNA' (-9) was observed that is related to people aged 0 - 15. So they are going to be considered as 'False'.\n",
    "## There were found 146 'NA' (-8) people. These are going to be considered as 'False' too.\n",
    "\n",
    "Bike_access_2019_update = {\n",
    "    1: True,          # Own a bicycle\n",
    "    2: True,          # Have regular use of a bicycle owned by someone else\n",
    "    3: False,         # Have no regular use of a bicycle\n",
    "    -10: 'no',        # DEAD\n",
    "    -9: False,        # 'DNA' (individuals aged 0-15) \n",
    "    -8: False         # 'NA' \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Bike_access2019'] = df_persons_NTS['Bike_access2019'].map(Bike_access_2019_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Marital status\" has:\n",
    "k = df_persons_NTS['Bike_access2019'].unique()\n",
    "print((k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Bike_access2019').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge both columns into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_person, person in df_persons_NTS.iterrows():\n",
    "    \n",
    "    if person['Bike_access2018'] == 'no':\n",
    "        df_persons_NTS.at[idx_person,'Bike_access'] = person['Bike_access2019']\n",
    "        \n",
    "    if person['Bike_access2019'] == 'no':\n",
    "        df_persons_NTS.at[idx_person,'Bike_access'] = person['Bike_access2018']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of married or couple and single individuals in the dataset\n",
    "df_persons_NTS.groupby('Bike_access').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Marital status\" has:\n",
    "l = df_persons_NTS['Bike_access'].unique()\n",
    "print(sorted(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS = df_persons_NTS.replace({'True': True, 'False': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Bike_access'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the total people in household and total children in household in order to identify individuals with children dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new columns in the dataframe:\n",
    "\n",
    "#Column with the total amount of people in the household\n",
    "df_persons_NTS[\"Total_People_in_household\"] = 0\n",
    "\n",
    "#Column with the total amoun of children in the household\n",
    "df_persons_NTS[\"Total_Children_in_household\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all Households unique ID values\n",
    "HouseholdID_list = df_persons_NTS['HouseholdID'].unique().tolist()\n",
    "\n",
    "#Create an empty list where the small blocks of dataframes will be stored\n",
    "df_persons_NE_OA_HID_temp = []\n",
    "\n",
    "#Create a variable that counts the number of households iterated\n",
    "household_counter = 0\n",
    "\n",
    "for HID_AreaOA in HouseholdID_list:\n",
    "    #Increase the value of the household_counter in 1\n",
    "    household_counter += 1\n",
    "    print(\"Number of HOUSEHOLD in iteration: \", (household_counter, len(HouseholdID_list)))\n",
    "    \n",
    "    \n",
    "    #Get only the PERSONS that belong to the same HID_AreaOA\n",
    "    persons_in_household = df_persons_NTS.loc[df_persons_NTS['HouseholdID'] == HID_AreaOA]\n",
    "    #print(df_persons_NE_OA_HID)\n",
    "\n",
    "    ##Do the calculus just HOUSEHOLD BY HOUSEHOLD\n",
    "    for idx_person_1, person_1 in persons_in_household.iterrows():\n",
    "        count_people = 1\n",
    "        if person_1['Age'] < 16:\n",
    "            count_children = 1\n",
    "        else:\n",
    "            count_children = 0\n",
    "        for idx_person_2, person_2 in persons_in_household.iterrows():\n",
    "            #If person_1 is different to person_2:\n",
    "            if (person_1['IndividualID'] != person_2['IndividualID']):\n",
    "                count_people += 1\n",
    "                #If person_1 is older than 16\n",
    "                if person_2['Age'] < 16:\n",
    "                    count_children += 1\n",
    "                     \n",
    "        #Update values in the person's row            \n",
    "        persons_in_household.at[idx_person_1,'Total_People_in_household'] = count_people\n",
    "        persons_in_household.at[idx_person_1,'Total_Children_in_household'] = count_children\n",
    "                        \n",
    "\n",
    "\n",
    "    #Append the dataframe into the temporal list\n",
    "    df_persons_NE_OA_HID_temp.append(persons_in_household)\n",
    "            \n",
    "  \n",
    "        \n",
    "#concatenate all persons (lists of the 'df_persons_NE_OA_HID_temp' list) in one dataframe\n",
    "df_persons_NE_Household_composition = pd.concat(df_persons_NE_OA_HID_temp, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS = df_persons_NE_Household_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column showing if an adult has children dependency\n",
    "df_persons_NTS[\"Children_dependency\"] = np.nan\n",
    "df_persons_NTS[\"Children_dependency\"] = df_persons_NTS[\"Children_dependency\"].astype('bool')   \n",
    "df_persons_NTS[\"Children_dependency\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def children_dependency(Age, Total_Children_in_household):\n",
    "    if ((Age >= 18) and (Total_Children_in_household > 0)):\n",
    "        Children_dependency = True\n",
    "    else:\n",
    "        Children_dependency = False\n",
    "    return Children_dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the lambda function \"Children_dependency\" to identify which adults have children dependencies\n",
    "df_persons_NTS['Children_dependency'] = df_persons_NTS.apply(lambda x: children_dependency(x['Age'], x['Total_Children_in_household']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the values that column \"Marital status\" has:\n",
    "m = df_persons_NTS['Children_dependency'].unique()\n",
    "print(sorted(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons_NTS['Children_dependency'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new dataframe containing only those columns that are relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person_NTS = df_persons_NTS[['IndividualID', 'HouseholdID', 'PSUID', 'SurveyYear',\n",
    "                       'Age', 'Sex', 'Marital_status', 'Children_dependency', \n",
    "                       'Total_People_in_household', 'Total_Children_in_household',\n",
    "                       'Economic_activity', 'Occupation', 'Income', 'Income_group',\n",
    "                       'Driving_license', 'Car_access', 'Bike_access']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the type of data in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person_NTS.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataframe as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as csv file:\n",
    "df_person_NTS_export_20220326_latest = df_person_NTS\n",
    "\n",
    "df_person_NTS_export_20220326_latest.to_csv(r'C:\\Users\\b9055315\\PhD_project\\UK_Data_Service\\NTS\\Generated_data_from_code\\df_person_NTS_export_20220326_latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df_person_NTS['Income_group'].unique()\n",
    "print(sorted(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as csv file:\n",
    "df_days_NTS_export_20220311 = df_days_NTS\n",
    "\n",
    "df_days_NTS_export_20220311.to_csv(r'C:\\Users\\b9055315\\PhD_project\\UK_Data_Service\\NTS\\Generated_data_from_code\\df_days_NTS_export_20220311.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as csv file:\n",
    "df_psu_NTS_export_20220311 = df_psu_NTS\n",
    "\n",
    "df_psu_NTS_export_20220311.to_csv(r'C:\\Users\\b9055315\\PhD_project\\UK_Data_Service\\NTS\\Generated_data_from_code\\df_psu_NTS_export_20220311.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_person_NTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read trip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_dir = r'' # use your path\n",
    "\n",
    "\n",
    "df_trip = pd.read_csv(\n",
    "    trip_dir,\n",
    "    sep='\\t',\n",
    "    usecols=['SurveyYear',\n",
    "             'TripID',\n",
    "             'DayID',\n",
    "             'IndividualID',\n",
    "             'HouseholdID',\n",
    "             'PSUID', \n",
    "             'NumStages',\n",
    "             'MainMode_B03ID',\n",
    "             'MainMode_B11ID',\n",
    "             'TripPurpose_B02ID',\n",
    "             'TripPurpose_B04ID',\n",
    "             ],\n",
    "#     dtype={\"W5\": np.float64,}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip_NTS = df_trip.loc[(df_trip['IndividualID'].isin(days_persons_NTS_list)) &\n",
    "                          (df_trip['PSUID'].isin(days_PSU_NTS_list)) &\n",
    "                         (df_trip['SurveyYear'] >= 2011) &\n",
    "                         (df_trip['SurveyYear'] <= 2019)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_trip_NTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip_NTS.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip_NTS['SurveyYear'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip_NTS['SurveyYear'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as csv file:\n",
    "df_trip_NTS_export_20220326 = df_trip_NTS\n",
    "\n",
    "df_trip_NTS_export_20220326.to_csv(r'') # use your file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip_NTS.loc[(df_trip_NTS['TripPurpose_B04ID'] == 3)].sort_values('IndividualID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip_NTS.loc[\n",
    "               (df_trip_NTS['HouseholdID'] == 2019006333)].sort_values(['IndividualID', 'DayID'], ascending=[True, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
