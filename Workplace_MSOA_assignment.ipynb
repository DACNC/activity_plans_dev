{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import time \n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV file containing the agents from SPENSER\n",
    "df_persons_SPENSER__dir = r'' # use your path\n",
    "df_persons_SPENSER__file = os.path.join(df_persons_SPENSER__dir, \"\")\n",
    "df_persons_SPENSER = pd.read_csv(df_persons_SPENSER__file, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV file containing the active employed people aged >=16 per MSOA level \n",
    "LC6107EW_MSOA_dir = r'' # use your path\n",
    "LC6107EW_MSOA_file = os.path.join(LC6107EW_MSOA_dir, \"\")\n",
    "df_LC6107EW = pd.read_csv(LC6107EW_MSOA_file, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LC6107EW.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep only relevant columns\n",
    "df_LC6107EW = df_LC6107EW[['geography_code','people']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV file \n",
    "O_D_msoa_NE_dir = r'' # use your path\n",
    "O_D_msoa_NE_file = os.path.join(O_D_msoa_NE_dir, \"\")\n",
    "df_O_D = pd.read_csv(O_D_msoa_NE_file, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV file containing the distances between msoa centroids (meters and miles) \n",
    "MSOA_lelvel_centroid_distances_dir = r'' # use your path\n",
    "MSOA_lelvel_centroid_distances_file = os.path.join(MSOA_lelvel_centroid_distances_dir, \"\")\n",
    "df_MSOA_lelvel_centroid_distances = pd.read_csv(MSOA_lelvel_centroid_distances_file, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MSOA_lelvel_centroid_distances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both dataframes to get the distances between MSOA centroids (meter and miles)\n",
    "# This distances were calculated using the road network\n",
    "df_O_D = pd.merge(df_O_D, df_MSOA_lelvel_centroid_distances,  how='left', left_on=['Origin','Destination'], right_on = ['msoa_origin', 'msoa_destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns\n",
    "df_O_D.drop(['msoa_origin', 'msoa_destination', 'distance_meters'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV file containing the matches between NTS and SPENSER:\n",
    "NTS_SPENSER_matched_dir = r'' # use your path\n",
    "NTS_SPENSER_matched_file = os.path.join(NTS_SPENSER_matched_dir, \"\")\n",
    "df_NTS_SPENSER_matched = pd.read_csv(NTS_SPENSER_matched_file, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NTS_SPENSER_matched.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_NTS_SPENSER_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of null values in the columns:\n",
    "df_NTS_SPENSER_matched.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV file containing the selected NTS days:\n",
    "NTS_days_dir = r'' # use your path\n",
    "NTS_days_file = os.path.join(NTS_days_dir, \"\")\n",
    "df_NTS_days = pd.read_csv(NTS_days_file, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_NTS_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all Days unique ID values\n",
    "days_selected_list = df_NTS_days['DayID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the file with the days related to each individual\n",
    "trips_dir = r'' # use your path\n",
    "\n",
    "\n",
    "df_NTS_trips = pd.read_csv(\n",
    "    trips_dir,\n",
    "    sep='\\t',\n",
    "    usecols=['TripID',\n",
    "             'DayID',               # ID given to all trips made by an individual on a given travel day - Created in SQL\n",
    "             'IndividualID',        # Individual unique ID - Created in SQL\n",
    "             'HouseholdID',         # Household unique ID - Created in SQL\n",
    "             'PSUID',               # PSU unique ID - Created in SQL\n",
    "             'JourSeq',             # Journey number on a given travel day\n",
    "             'NumStages',           # Number of stages - actual number\n",
    "             'MainMode_B04ID',      # Main mode of travel - publication table breakdown - 13 categories\n",
    "             'TripPurpTo_B01ID',   # Trip purpose - full list - 23 categories\n",
    "             'TripStartHours',      # Trip start time - hours component\n",
    "             'TripStartMinutes',    # Trip start time - minutes component\n",
    "             'TripStart',           # Trip start time - minutes past midnight\n",
    "             'TripEndHours',        # Trip end time - hours component\n",
    "             'TripEndMinutes',      # Trip end time - minutes component\n",
    "             'TripEnd',             # Trip end time - minutes past midnight\n",
    "             'TripDisIncSW',        # Trip distance - including short walk - miles - actual distance\n",
    "             'TripTotalTime'        # Total trip time - minutes - actual time\n",
    "             ]          \n",
    ")\n",
    "#persons_in.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_NTS_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only those days that belong to the people selected before\n",
    "df_NTS_trips = df_NTS_trips.loc[(df_NTS_trips['DayID'].isin(days_selected_list))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_NTS_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update transpor mode\n",
    "mode_mapping = {\n",
    "    1: 'walk',\n",
    "     2: 'bike',\n",
    "     3: 'car',  #'Car/van driver'\n",
    "     4: 'car_passenger',  #'Car/van passenger'\n",
    "     5: 'motorcycle',  \n",
    "     6: 'car',  #'Other private transport',\n",
    "     7: 'bus', #Bus in London',\n",
    "     8: 'bus', #'Other local bus',\n",
    "     9: 'bus', #'Non-local bus',\n",
    "     10: 'metro', #'London Underground',\n",
    "     11: 'train', #'Surface Rail',\n",
    "     12: 'car',  #'Taxi/minicab',\n",
    "     13: 'metro', #'Other public transport',\n",
    "     -10: 'DEAD',\n",
    "     -8: 'NA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NTS_trips['MainMode_B04ID'] = df_NTS_trips['MainMode_B04ID'].map(mode_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_modes_list = df_NTS_trips['MainMode_B04ID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_modes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purp_mapping = {\n",
    "    1: 'work',\n",
    "     2: 'work',  #'In course of work',\n",
    "     3: 'education',\n",
    "     4: 'food_shop',  #'Food shopping',\n",
    "     5: 'shop',  #'Non food shopping',\n",
    "     6: 'medical', #'Personal business medical',\n",
    "     7: 'eat',  #'Personal business eat/drink',\n",
    "     8: 'other',  #'Personal business other',\n",
    "     9: 'eat',  #'Eat/drink with friends',\n",
    "     10: 'other',  #'Visit friends',\n",
    "     11: 'leisure',  #'Other social',\n",
    "     12: 'leisure',  #'Entertain/ public activity',\n",
    "     13: 'leisure_sport',  #'Sport: participate',\n",
    "     14: 'home',  #'Holiday: base',\n",
    "     15: 'leisure_sport',  #'Day trip/just walk',\n",
    "     16: 'leisure',  #'Other non-escort',\n",
    "     17: 'escort',  #'Escort home',\n",
    "     18: 'escort',  #'Escort work',\n",
    "     19: 'escort',  #'Escort in course of work',\n",
    "     20: 'escort',  #'Escort education',\n",
    "     21: 'escort',  #'Escort shopping/personal business',\n",
    "     22: 'escort',  #'Other escort',\n",
    "     23: 'home',  #'Home',\n",
    "     -10: 'DEAD',\n",
    "     -8: 'NA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NTS_trips['TripPurpTo_B01ID'] = df_NTS_trips['TripPurpTo_B01ID'].map(purp_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NTS_trips['TripPurpTo_B01ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only those individuals that are employed and older than 15 years.\n",
    "df_persons_SPENSER_employed = df_persons_SPENSER.loc[(df_persons_SPENSER['Age'] >= 16) & (df_persons_SPENSER['Economic_activity'] == 'Employed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_persons_SPENSER_employed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_saved = 'workplace_destination.csv' # in case\n",
    "O_D_file_saved = 'O_D_msoa_NE_all_updated.csv' # in case\n",
    "workplace_destination_round2 = 'workplace_destination_round2.csv' # in case\n",
    "#workplace_destination_round3 = 'workplace_destination_round3.csv' # in case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "individuals_matched_list = []\n",
    "msoa_list = df_persons_SPENSER['Area_MSOA'].unique()\n",
    "spenser_id_list = []\n",
    "counter = 0\n",
    "\n",
    "for msoa_code in msoa_list:\n",
    "    \n",
    "    \n",
    "    counter += 1\n",
    "    clear_output(wait=True)\n",
    "    print(f' {counter} of {len(msoa_list)}, MSOA name: {msoa_code}')\n",
    "    print(msoa_code)\n",
    "    \n",
    "    ## Identify those agents in the MSOA level, (previously selected: older than 15 and employed)\n",
    "    df_persons_SPENSER_msoa = df_persons_SPENSER_employed.loc[(df_persons_SPENSER_employed['Area_MSOA']== msoa_code) & ~(df_persons_SPENSER_employed['PID_AreaMSOA'].isin(spenser_id_list)) ]\n",
    "    \n",
    "    # List the IDs of the agents selected\n",
    "    persons_ID_SPENSER_msoa_list = df_persons_SPENSER_msoa['PID_AreaMSOA'].unique().tolist()\n",
    "    \n",
    "    # count the number of agents selected\n",
    "    agents_2019_selected = len(df_persons_SPENSER_msoa)\n",
    "    \n",
    "\n",
    "    ## Identify those people (census 2011) in the MSOA level that are employed and older than 16 years old\n",
    "    df_LC6107EW_msoa = df_LC6107EW.loc[(df_LC6107EW['geography_code'] == msoa_code)]\n",
    "    \n",
    "    # Get the number of people that are employed and older than 15 years old in the selected MSOA level\n",
    "    people_2011_selected = df_LC6107EW_msoa['people'].values[0]\n",
    "    \n",
    "\n",
    "    # Calculate the ratio of people between 2019 and 2011 per MSOA level\n",
    "    ## This value is to update the number of people travelling in the NE from the selected MSOA level\n",
    "    ### We assume a linear incrase or decrase of people using each transport mode from 2011 to 2019\n",
    "    ratio_people_2019_2011 = agents_2019_selected / people_2011_selected\n",
    "    \n",
    "    \n",
    "\n",
    "    #Select the rows of the O_D_matrix that is related to the selected msoa level:\n",
    "    df_O_D_msoa = df_O_D.loc[(df_O_D['Origin'] == msoa_code)]\n",
    "    \n",
    "\n",
    "    ## update the values to be assinged from 2011 to 2019!!\n",
    "    df_O_D_msoa['car'] = round((df_O_D_msoa['car'] * ratio_people_2019_2011),0).astype(int)\n",
    "    df_O_D_msoa['bus'] = round((df_O_D_msoa['bus'] * ratio_people_2019_2011),0).astype(int)\n",
    "    df_O_D_msoa['bike'] = round((df_O_D_msoa['bike'] * ratio_people_2019_2011),0).astype(int)\n",
    "    df_O_D_msoa['walk'] = round((df_O_D_msoa['walk'] * ratio_people_2019_2011),0).astype(int)\n",
    "    df_O_D_msoa['motorcycle'] = round((df_O_D_msoa['motorcycle'] * ratio_people_2019_2011),0).astype(int)\n",
    "    df_O_D_msoa['car_passenger'] = round((df_O_D_msoa['car_passenger'] * ratio_people_2019_2011),0).astype(int)\n",
    "    df_O_D_msoa['train'] = round((df_O_D_msoa['train'] * ratio_people_2019_2011),0).astype(int)\n",
    "    df_O_D_msoa['metro'] = round((df_O_D_msoa['metro'] * ratio_people_2019_2011),0).astype(int)\n",
    "    df_O_D_msoa['total'] = df_O_D_msoa['car'] + df_O_D_msoa['bus'] + df_O_D_msoa['bike'] + df_O_D_msoa['walk'] + df_O_D_msoa['motorcycle'] + df_O_D_msoa['car_passenger'] + df_O_D_msoa['train'] + df_O_D_msoa['metro']\n",
    "    \n",
    "    \n",
    "    # save the updated data in a csv file\n",
    "    df_O_D_msoa.to_csv(O_D_file_saved, encoding='utf-8', mode='a', index=False, header=False)\n",
    "            \n",
    "\n",
    "    # Sort df_O_D_msoa by distance (shorter distances in top)\n",
    "    df_O_D_msoa = df_O_D_msoa.sort_values(['distance_miles'], ascending = [True])\n",
    "    \n",
    "    ################################\n",
    "    \n",
    "\n",
    "    \n",
    "    ## loop through each of the transport modes and assign each individual a destination:\n",
    "    for transport_mode in transport_modes_list:\n",
    "\n",
    "        ## Select those matched individuals between NTS ns SPENSER and \n",
    "        df_NTS_SPENSER_matched_msoa = df_NTS_SPENSER_matched.loc[(df_NTS_SPENSER_matched['PID_AreaMSOA'].isin(persons_ID_SPENSER_msoa_list)) & ~ (df_NTS_SPENSER_matched['PID_AreaMSOA'].isin(spenser_id_list))]\n",
    "        \n",
    "        # List the IDs of the agents selected\n",
    "        persons_ID_NTS_msoa_list = df_NTS_SPENSER_matched_msoa['IndividualID'].unique().tolist()\n",
    "    \n",
    "        # list of DayID of the agents selected\n",
    "        days_ID_NTS_msoa_list = df_NTS_SPENSER_matched_msoa['DayID'].unique().tolist()\n",
    "    \n",
    "        \n",
    "        \n",
    "        ## Select only those trips that belong to the people and days selected before +  purpose = work + mode = transport_mode\n",
    "        df_NTS_trips_selected = df_NTS_trips.loc[((df_NTS_trips['IndividualID'].isin(persons_ID_NTS_msoa_list)) & (df_NTS_trips['TripPurpTo_B01ID'] == 'work') & (df_NTS_trips['DayID'].isin(days_ID_NTS_msoa_list)) & (df_NTS_trips['MainMode_B04ID'] == transport_mode))]  \n",
    "        \n",
    "        \n",
    "        ## Remove duplicate rows based on IndividualID and DayID (if they have more than one trip for purpose =work, keep only the first)\n",
    "        df_NTS_trips_selected = df_NTS_trips_selected.drop_duplicates(subset=['IndividualID', 'DayID'], keep=\"first\")\n",
    "        \n",
    "        ## Create a new dataframe containing only the relevant columns\n",
    "        df_NTS_trips_selected_short = df_NTS_trips_selected[['IndividualID', 'DayID', 'TripDisIncSW', 'MainMode_B04ID', 'TripPurpTo_B01ID']]\n",
    "        \n",
    "\n",
    "        ## Merge dataframes to combine df_NTS_SPENSER_matched_msoa with the distances travelled by each individual        \n",
    "        df_NTS_SPENSER_matched_msoa_transportmode = pd.merge(df_NTS_SPENSER_matched_msoa, df_NTS_trips_selected_short,  how='left', left_on=['IndividualID','DayID'], right_on = ['IndividualID','DayID'])\n",
    "        \n",
    "        ## Drop those rows where there are null values\n",
    "        df_NTS_SPENSER_matched_msoa_transportmode = df_NTS_SPENSER_matched_msoa_transportmode.dropna(axis=0, subset=['MainMode_B04ID'])\n",
    "        \n",
    "        ## Keep only relevant columns\n",
    "        df_NTS_SPENSER_matched_msoa_transportmode = df_NTS_SPENSER_matched_msoa_transportmode[['PID_AreaMSOA', 'IndividualID', 'DayID', 'TripDisIncSW', 'MainMode_B04ID', 'TripPurpTo_B01ID']]\n",
    "        \n",
    "        ## Sort values by distance\n",
    "        df_NTS_SPENSER_matched_msoa_transportmode = df_NTS_SPENSER_matched_msoa_transportmode.sort_values(['TripDisIncSW'], ascending = [True])\n",
    "        \n",
    "        # At this stage we have identified the spenser people (msoa level, aged >=16 and employed) that travel to work by \"transport_mode\" selected in the previous 'for loop'\n",
    "        \n",
    "        \n",
    "        ########\n",
    "        ## Now we need to match them msoa level they go based on the transport mode they use\n",
    "        ### loop through the df_O_D_msoa matrix and select the value of the column related to the transport mode selected in the first for loop\n",
    "        \n",
    "\n",
    "        \n",
    "        counter_people_selected_for_transport_mode = 0\n",
    "        \n",
    "        for idx_msoa, msoa_row in df_O_D_msoa.iterrows():\n",
    "            \n",
    "            # Select the people that travel by the transpor_mode selected in the previous for loop\n",
    "            people_in_transport_mode = msoa_row[transport_mode]\n",
    "            \n",
    "            \n",
    "            msoa_destination = msoa_row['Destination']\n",
    "            \n",
    "\n",
    "            # Select the top \"x\" values\n",
    "            # If there are more people in the synthetic population than in the O_C_matrix:\n",
    "            if (len(df_NTS_SPENSER_matched_msoa_transportmode) >= people_in_transport_mode):\n",
    "            \n",
    "            \n",
    "                df_NTS_SPENSER_matched_msoa_transportmode_matched = df_NTS_SPENSER_matched_msoa_transportmode.head(people_in_transport_mode)\n",
    "            \n",
    "            # If there are less, select the remaining ones           \n",
    "            else:\n",
    "                \n",
    "                df_NTS_SPENSER_matched_msoa_transportmode_matched = df_NTS_SPENSER_matched_msoa_transportmode\n",
    "            \n",
    "\n",
    "            counter_people_selected_for_transport_mode += len(df_NTS_SPENSER_matched_msoa_transportmode_matched)\n",
    "            \n",
    "            # Concatenate the selected ones with the people from the same age and OA area\n",
    "            df_concatenated = (pd.concat([df_NTS_SPENSER_matched_msoa_transportmode,df_NTS_SPENSER_matched_msoa_transportmode_matched]))\n",
    "            \n",
    "            \n",
    "            #Remove duplicates BUT keep the same names of the dataframes used after selecting the OAarea, age and sex\n",
    "            df_NTS_SPENSER_matched_msoa_transportmode = df_concatenated.drop_duplicates(subset='PID_AreaMSOA', keep = False)\n",
    "            \n",
    "            ## update the value\n",
    "            df_NTS_SPENSER_matched_msoa_transportmode_matched['Origin'] = msoa_code\n",
    "            \n",
    "            ## update the value\n",
    "            df_NTS_SPENSER_matched_msoa_transportmode_matched['Destination'] = msoa_destination\n",
    "            \n",
    "            # update the value\n",
    "            df_NTS_SPENSER_matched_msoa_transportmode_matched['O_D_transport_mode'] = transport_mode\n",
    "            \n",
    "            #Remove duplicates BUT keep the same names of the dataframes used after selecting the OAarea, age and sex\n",
    "            df_NTS_SPENSER_matched_msoa_transportmode_matched = df_NTS_SPENSER_matched_msoa_transportmode_matched.drop_duplicates(subset='PID_AreaMSOA', keep = 'first')\n",
    "            \n",
    "\n",
    "            \n",
    "            ## loop through the people selected and save them in a list\n",
    "            for idx_person_matched, person_matched in df_NTS_SPENSER_matched_msoa_transportmode_matched.iterrows():\n",
    "            \n",
    "                spenser_id_list.append(person_matched['PID_AreaMSOA'])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # save the data in a csv file\n",
    "            df_NTS_SPENSER_matched_msoa_transportmode_matched.to_csv(file_saved, encoding='utf-8', mode='a', index=False, header=False)\n",
    "            \n",
    "\n",
    "\n",
    "print('Code has been finished. Check results!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header =[\"PID_AreaMSOA\", \"IndividualID\", \"DayID\", \"TripDisIncSW\", \"MainMode_B04ID\", \"TripPurpTo_B01ID\", \"Origin\", \"Destination\", \"O_D_transport_mode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV file containing the agents from SPENSER\n",
    "df_NTS_SPENSER_matched_msoa_transportmode_matched_dir = r'' # use your path\n",
    "df_NTS_SPENSER_matched_msoa_transportmode_matched_file = os.path.join(df_NTS_SPENSER_matched_msoa_transportmode_matched_dir, \"workplace_destination.csv\")\n",
    "df_NTS_SPENSER_matched_msoa_transportmode_matched = pd.read_csv(df_NTS_SPENSER_matched_msoa_transportmode_matched_file, index_col=None, header=None, names= header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_NTS_SPENSER_matched_msoa_transportmode_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_NTS_SPENSER_matched_msoa_transportmode_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_first_results = pd.DataFrame({'count' : df_NTS_SPENSER_matched_msoa_transportmode_matched.groupby( ['Origin','Destination'] ).size()}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_first_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_first_results['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_2 = [\"Origin\", \"Destination\", \"car\", \"bus\", \"bike\", \"walk\", \"motorcycle\", \"car_passenger\", \"train\", \"metro\", \"total\", \"distance_miles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV file containing the agents from SPENSER\n",
    "O_D_msoa_NE_updated_dir = r'' # use your path\n",
    "O_D_msoa_NE_updated_file = os.path.join(O_D_msoa_NE_updated_dir, \"O_D_msoa_NE_all_updated.csv\")\n",
    "df_O_D_msoa_NE_updated = pd.read_csv(O_D_msoa_NE_updated_file, index_col=None, header=None, names= header_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated['total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both dataframes\n",
    "df_O_D_msoa_NE_updated_merged = pd.merge(df_O_D_msoa_NE_updated, df_grouped_first_results,  how='left', left_on=['Origin', 'Destination'], right_on = ['Origin', 'Destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repalce Nan values by 0\n",
    "df_O_D_msoa_NE_updated_merged = df_O_D_msoa_NE_updated_merged.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new column with the remaining number of people to be assigned to each MSOA, based on data from the O_D matrix 2011\n",
    "df_O_D_msoa_NE_updated_merged['Remaining'] = df_O_D_msoa_NE_updated_merged['total'] - df_O_D_msoa_NE_updated_merged['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant columns\n",
    "df_O_D_msoa_NE_updated_merged = df_O_D_msoa_NE_updated_merged[['Origin', 'Destination', 'total','Remaining', 'distance_miles']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged['Remaining'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep only those columns when Remaining > 0\n",
    "df_O_D_msoa_NE_updated_merged = df_O_D_msoa_NE_updated_merged.loc[df_O_D_msoa_NE_updated_merged['Remaining'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_O_D_msoa_NE_updated_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged['Remaining'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged['Remaining'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged['Remaining'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify those spenser people that have not been selected a MSOA workplace yet.\n",
    "spenser_id_already_selected_list = df_NTS_SPENSER_matched_msoa_transportmode_matched['PID_AreaMSOA'].unique().tolist()\n",
    "\n",
    "\n",
    "df_persons_SPENSER_employed_remaining = df_persons_SPENSER_employed.loc[(~df_persons_SPENSER_employed['PID_AreaMSOA'].isin(spenser_id_already_selected_list))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_persons_SPENSER_employed_remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for msoa_code in msoa_list:\n",
    "    \n",
    "    # If there is still at least one row available to be assigned to an employed, do the following.\n",
    "    ## else: break\n",
    "    if (len(df_O_D_msoa_NE_updated_merged) > 0):\n",
    "    \n",
    "        counter += 1\n",
    "        clear_output(wait=True)\n",
    "        print(f' {counter} of {len(msoa_list)}, MSOA name: {msoa_code}')\n",
    "\n",
    "        ## Identify those remaining agents in the MSOA level\n",
    "        df_persons_SPENSER_msoa = df_persons_SPENSER_employed_remaining.loc[(df_persons_SPENSER_employed_remaining['Area_MSOA']== msoa_code)]\n",
    "\n",
    "\n",
    "        # List the IDs of the agents selected\n",
    "        persons_ID_SPENSER_msoa_list = df_persons_SPENSER_msoa['PID_AreaMSOA'].unique().tolist()\n",
    "\n",
    "\n",
    "\n",
    "        ## Select those matched individuals between NTS and SPENSER  \n",
    "        df_NTS_SPENSER_matched_msoa = df_NTS_SPENSER_matched.loc[(df_NTS_SPENSER_matched['PID_AreaMSOA'].isin(persons_ID_SPENSER_msoa_list))]\n",
    "\n",
    "        # List the IDs of the agents selected\n",
    "        persons_ID_NTS_msoa_list = df_NTS_SPENSER_matched_msoa['IndividualID'].unique().tolist()\n",
    "\n",
    "        # list of DayID of the agents selected\n",
    "        days_ID_NTS_msoa_list = df_NTS_SPENSER_matched_msoa['DayID'].unique().tolist()\n",
    "\n",
    "\n",
    "\n",
    "        ## Select only those trips that belong to the people and days selected before and trip purpose = 'work'\n",
    "        df_NTS_trips_selected = df_NTS_trips.loc[((df_NTS_trips['IndividualID'].isin(persons_ID_NTS_msoa_list)) & (df_NTS_trips['DayID'].isin(days_ID_NTS_msoa_list)) & (df_NTS_trips['TripPurpTo_B01ID'] == 'work'))]  \n",
    "\n",
    "        # Sort df_NTS_trips_selected by distance\n",
    "        df_NTS_trips_selected = df_NTS_trips_selected.sort_values(['TripDisIncSW'], ascending = [False])\n",
    "\n",
    "        ## Remove duplicate rows based on IndividualID and DayID (if they have more than one trip, keep only the first (the longest))\n",
    "        df_NTS_trips_selected = df_NTS_trips_selected.drop_duplicates(subset=['IndividualID', 'DayID'], keep=\"first\")\n",
    "\n",
    "        ## Create a new dataframe containing only the relevant columns\n",
    "        df_NTS_trips_selected_short = df_NTS_trips_selected[['IndividualID','DayID', 'TripDisIncSW', 'MainMode_B04ID', 'TripPurpTo_B01ID']]\n",
    "\n",
    "\n",
    "        ## Merge dataframes to combine df_NTS_SPENSER_matched_msoa with the distances travelled by each individual        \n",
    "        df_NTS_SPENSER_matched_msoa_remaining = pd.merge(df_NTS_SPENSER_matched_msoa, df_NTS_trips_selected_short,  how='left', left_on=['IndividualID','DayID'], right_on = ['IndividualID','DayID'])\n",
    "\n",
    "\n",
    "\n",
    "        ## Drop those rows where there are null values (for example, with the column MainMode_B04ID. It means that that individual does not have any trip assigned)\n",
    "        df_NTS_SPENSER_matched_msoa_remaining = df_NTS_SPENSER_matched_msoa_remaining.dropna(axis=0, subset=['MainMode_B04ID'])\n",
    "\n",
    "        ## Keep only relevant columns\n",
    "        df_NTS_SPENSER_matched_msoa_remaining = df_NTS_SPENSER_matched_msoa_remaining[['PID_AreaMSOA', 'IndividualID', 'DayID', 'TripDisIncSW', 'MainMode_B04ID', 'TripPurpTo_B01ID']]\n",
    "\n",
    "        ## Sort values by distance\n",
    "        df_NTS_SPENSER_matched_msoa_remaining = df_NTS_SPENSER_matched_msoa_remaining.sort_values(['TripDisIncSW'], ascending = [True])\n",
    "\n",
    "\n",
    "        ### At this stage, we have the people in the msoa level (origin) that need to be assinged a msoa area for work (destination). based on their distance travelled.\n",
    "        ############################################\n",
    "\n",
    "\n",
    "        ## Loop through each individual and match their travelled distance to the closest MSOA area:\n",
    "        for idx_individual, NTS_SPENSER_individual in df_NTS_SPENSER_matched_msoa_remaining.iterrows():\n",
    "\n",
    "            ##Get their distance travelled\n",
    "            individual_distance_travelled = NTS_SPENSER_individual['TripDisIncSW']\n",
    "\n",
    "\n",
    "            # Get the possible msoa destinations based on the msoa origin value\n",
    "            df_O_D_msoa_NE_updated_merged_msoa_unique = df_O_D_msoa_NE_updated_merged.loc[(df_O_D_msoa_NE_updated_merged['Origin'] == msoa_code) & (df_O_D_msoa_NE_updated_merged['Remaining'] > 0)]\n",
    "\n",
    "\n",
    "\n",
    "            if (len(df_O_D_msoa_NE_updated_merged_msoa_unique) > 0):\n",
    "\n",
    "\n",
    "                # Find the closest MSOA level destination from \"df_O_D_msoa_NE_updated_merged\", based on the \"distance_miles\" column\n",
    "                O_D_msoa_destination_row_index = df_O_D_msoa_NE_updated_merged_msoa_unique['distance_miles'].sub(individual_distance_travelled).abs().idxmin()\n",
    "\n",
    "\n",
    "                df_O_D_msoa_destination_chosen = df_O_D_msoa_NE_updated_merged_msoa_unique.loc[O_D_msoa_destination_row_index]\n",
    "\n",
    "                df_O_D_msoa_destination_chosen = df_O_D_msoa_destination_chosen.to_frame().T\n",
    "\n",
    "\n",
    "                # Identify the current number of people to be assigned this MSOA level to travel based on the O_D matrix\n",
    "                current_remainig = df_O_D_msoa_destination_chosen.iloc[0]['Remaining']\n",
    "                \n",
    "                \n",
    "                #print(current_remainig)\n",
    "                \n",
    "\n",
    "                # Remove one unit of the current remainig people to be assigned to that MSOA level\n",
    "                ## the person selected in the for loop will take this place and should be not accesible for the others.\n",
    "                df_O_D_msoa_NE_updated_merged.at[O_D_msoa_destination_row_index,'Remaining'] = current_remainig - 1\n",
    "                \n",
    "                \n",
    "                #print(df_O_D_msoa_NE_updated_merged.at[O_D_msoa_destination_row_index,'Remaining'])\n",
    "                \n",
    "                #sys.exit()\n",
    "\n",
    "                ## Create two new columns in the dataframe\n",
    "                NTS_SPENSER_individual[\"Origin\"] = df_O_D_msoa_destination_chosen.iloc[0]['Origin']\n",
    "                NTS_SPENSER_individual[\"Destination\"] = df_O_D_msoa_destination_chosen.iloc[0]['Destination']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                df_NTS_SPENSER_individual = pd.DataFrame([NTS_SPENSER_individual])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ## Save the individual in a csv file\n",
    "                df_NTS_SPENSER_individual.to_csv(workplace_destination_round2, encoding='utf-8', mode='a', index=False, header=False)\n",
    "\n",
    "\n",
    "\n",
    "                ## if the number of remaining people to be assinged to that MSOA level is 0, then drop the column\n",
    "                if (df_O_D_msoa_NE_updated_merged.at[O_D_msoa_destination_row_index,'Remaining'] == 0):\n",
    "\n",
    "                    df_O_D_msoa_NE_updated_merged = df_O_D_msoa_NE_updated_merged.drop(labels= O_D_msoa_destination_row_index, axis=0)\n",
    "\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print('All available slots have been assigned. Process is finished.')\n",
    "        break\n",
    "            \n",
    "print('Code has been finished. Check results, amigo!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_3 =[\"PID_AreaMSOA\", \"IndividualID\", \"DayID\", \"TripDisIncSW\", \"MainMode_B04ID\", \"TripPurpTo_B01ID\", \"Origin\", \"Destination\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV file \n",
    "workplace_destination_round2_dir = r'' # use your path\n",
    "workplace_destination_round2_file = os.path.join(workplace_destination_round2_dir, \"workplace_destination_round2.csv\")\n",
    "df_workplace_destination_round2 = pd.read_csv(workplace_destination_round2_file, index_col=None, header=None, names= header_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_workplace_destination_round2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_workplace_destination_round2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(len(df_NTS_SPENSER_matched_msoa_transportmode_matched) + len(df_workplace_destination_round2)) /len(df_persons_SPENSER_employed) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df_NTS_SPENSER_matched_msoa_transportmode_matched) + len(df_workplace_destination_round2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged['Remaining'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged['Remaining'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged['Remaining'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_O_D_msoa_NE_updated_merged.loc[df_O_D_msoa_NE_updated_merged['Remaining'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = df_O_D_msoa_NE_updated_merged.loc[df_O_D_msoa_NE_updated_merged['Destination'] =='E02001731']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa['Remaining'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_NTS_SPENSER_matched_msoa_transportmode_matched, df_workplace_destination_round2]\n",
    "\n",
    "result_2_rounds = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_2_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2_rounds_short = result_2_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2_rounds_short = result_2_rounds_short[['PID_AreaMSOA', 'IndividualID', 'DayID', 'Origin', 'Destination']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2_rounds_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2_rounds_short.to_csv(r'', encoding='utf-8', mode='a', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "#####################\n",
    "\n",
    "\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate the number of employed people per MSOA level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed = df_persons_SPENSER_employed.groupby(['Area_MSOA'], sort=False).size().reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_msoa_employed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. calculate the number of employed people commuting within the NE per MSOA level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2_rounds_short['msoa'] = result_2_rounds_short['PID_AreaMSOA'].str.split('_').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE = result_2_rounds_short.groupby(['msoa'], sort=False).size().reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge dataframes to combine df_NTS_SPENSER_matched_msoa with the distances travelled by each individual        \n",
    "df_NTS_SPENSER_matched_msoa_remaining = pd.merge(df_NTS_SPENSER_matched_msoa, df_NTS_trips_selected_short,  how='left', left_on=['IndividualID','DayID'], right_on = ['IndividualID','DayID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019 = pd.merge(df_msoa_employed, df_msoa_employed_commutingNE, how='left', left_on=['Area_MSOA'], right_on = ['msoa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019.rename(columns={'Count_x': 'employed_active', 'Count_y': 'people_commuting_NE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019 = df_msoa_employed_commutingNE_comp_2019[['Area_MSOA','employed_active','people_commuting_NE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019['percentage_people_commuting_NE_2019'] = round(df_msoa_employed_commutingNE_comp['people_commuting_NE'] / df_msoa_employed_commutingNE_comp['employed_active']  *100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019['people_commuting_NE'].sum()/df_msoa_employed_commutingNE_comp_2019['employed_active'].sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019['percentage_people_commuting_NE_2019'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019['percentage_people_commuting_NE_2019'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_comp_2019['percentage_people_commuting_NE_2019'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read CSV file containing the agents from SPENSER\n",
    "perc_employed_commuting_NE_2011__dir = r'C:\\Users\\b9055315\\PhD_project\\UK_Data_Service\\NTS\\Generated_data_from_code\\workplace_destination' # use your path\n",
    "perc_employed_commuting_NE_2011__file = os.path.join(perc_employed_commuting_NE_2011__dir, \"perc_employed_commuting_NE_2011.csv\")\n",
    "df_perc_employed_commuting_NE_2011 = pd.read_csv(perc_employed_commuting_NE_2011__file, index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perc_employed_commuting_NE_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson = pd.merge(df_perc_employed_commuting_NE_2011, df_msoa_employed_commutingNE_comp_2019, how='left', left_on=['msoa_code'], right_on = ['Area_MSOA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson = df_msoa_employed_commutingNE_year_comparisson[['msoa_code', 'percentage_people_commuting_NE', 'percentage_people_commuting_NE_2019']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson.rename(columns={'percentage_people_commuting_NE': 'percentage_people_commuting_NE_2011'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson['percentage_diff'] = df_msoa_employed_commutingNE_year_comparisson['percentage_people_commuting_NE_2011'] - df_msoa_employed_commutingNE_year_comparisson['percentage_people_commuting_NE_2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson['percentage_diff'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson['percentage_diff'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson.to_csv(r'C:\\Users\\b9055315\\PhD_project\\UK_Data_Service\\NTS\\Generated_data_from_code\\workplace_destination\\sixth_attempt\\msoa_employed_commutingNE_year_comparisson.csv', encoding='utf-8', mode='a', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson.sort_values('percentage_diff', ascending=True).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msoa_employed_commutingNE_year_comparisson.loc[(df_msoa_employed_commutingNE_year_comparisson['percentage_diff'] < 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_msoa_employed_commutingNE_year_comparisson.loc[(df_msoa_employed_commutingNE_year_comparisson['percentage_diff'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['msoa_code'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
